# Default Sidecar Configuration
# For Llama-2-7B style models

# Model dimensions (will be auto-detected from model)
d_head: 128
n_heads: 32

# Compression window
window_size: 64

# Encoder architecture
encoder_type: transformer  # Options: transformer, gin, mlp
encoder_hidden_dim: 256
encoder_num_layers: 3
encoder_num_heads: 4
encoder_dropout: 0.1
encoder_ffn_ratio: 4.0

# Aggregator
aggregator_type: set_transformer  # Options: set_transformer, attention_pool, mean_pool
aggregator_num_heads: 4
aggregator_num_inducing: 8

# Architecture options
use_layer_norm: true
use_residual: true
position_encoding: learned  # Options: sinusoidal, learned, rope, none
output_projection: true

# Precision
dtype: bfloat16

